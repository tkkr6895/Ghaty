{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb6e8e74",
   "metadata": {},
   "source": [
    "# Western Ghats Historical LULC Analysis (1985-2020)\n",
    "\n",
    "**Objective**: Analyze long-term land use and land cover changes in the Western Ghats using Google Earth Engine's GLC-FCS30D dataset at 5-year intervals.\n",
    "\n",
    "**Key Features**:\n",
    "- Historical analysis from 1985 to 2020\n",
    "- 5-year interval data for long-term trend detection\n",
    "- 30-meter resolution global land cover dataset\n",
    "- Comprehensive temporal analysis spanning 35 years\n",
    "- Integration with Dynamic World results for complete picture\n",
    "\n",
    "**Technical Approach**:\n",
    "- GLC-FCS30D dataset from Google Earth Engine\n",
    "- 5-year composite analysis (1985, 1990, 1995, 2000, 2005, 2010, 2015, 2020)\n",
    "- Area calculations and change detection\n",
    "- Statistical analysis and visualization\n",
    "- Export capabilities for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad63940",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (3.13.2) (Python 3.13.2)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# SETUP AND IMPORTS\n",
    "import ee\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "print(\"Initializing Google Earth Engine...\")\n",
    "try:\n",
    "    # Initialize Earth Engine\n",
    "    ee.Initialize(project='ee-tkkrfirst')\n",
    "    print(\"SUCCESS: Earth Engine initialized\")\n",
    "    \n",
    "    # Load GLC-FCS30D dataset\n",
    "    glc_fcs_annual = ee.ImageCollection(\"projects/sat-io/open-datasets/GLC-FCS30D/annual\")\n",
    "    glc_fcs_five_year = ee.ImageCollection(\"projects/sat-io/open-datasets/GLC-FCS30D/five-years-map\")\n",
    "    \n",
    "    print(\"SUCCESS: GLC-FCS30D dataset loaded\")\n",
    "    \n",
    "    # Define GLC-FCS30D land cover classes\n",
    "    # Based on GLC-FCS30D classification scheme\n",
    "    GLC_CLASSES = {\n",
    "        10: 'Rainfed cropland',\n",
    "        11: 'Herbaceous cover cropland',\n",
    "        12: 'Tree or shrub cover cropland',\n",
    "        20: 'Irrigated cropland',\n",
    "        51: 'Open evergreen broadleaved forest',\n",
    "        52: 'Closed evergreen broadleaved forest',\n",
    "        61: 'Open deciduous broadleaved forest',\n",
    "        62: 'Closed deciduous broadleaved forest',\n",
    "        71: 'Open evergreen needle-leaved forest',\n",
    "        72: 'Closed evergreen needle-leaved forest',\n",
    "        81: 'Open deciduous needle-leaved forest',\n",
    "        82: 'Closed deciduous needle-leaved forest',\n",
    "        91: 'Open mixed leaf forest',\n",
    "        92: 'Closed mixed leaf forest',\n",
    "        120: 'Shrubland',\n",
    "        121: 'Evergreen shrubland',\n",
    "        122: 'Deciduous shrubland',\n",
    "        130: 'Grassland',\n",
    "        140: 'Lichens and mosses',\n",
    "        150: 'Sparse vegetation',\n",
    "        152: 'Sparse shrubland',\n",
    "        153: 'Sparse herbaceous',\n",
    "        181: 'Swamp',\n",
    "        182: 'Marsh',\n",
    "        183: 'Flooded flat',\n",
    "        184: 'Saline',\n",
    "        185: 'Mangrove',\n",
    "        186: 'Salt marsh',\n",
    "        187: 'Tidal flat',\n",
    "        190: 'Impervious surfaces',\n",
    "        200: 'Bare areas',\n",
    "        201: 'Consolidated bare areas',\n",
    "        202: 'Unconsolidated bare areas',\n",
    "        210: 'Water body',\n",
    "        220: 'Permanent ice and snow'\n",
    "    }\n",
    "    \n",
    "    print(f\"GLC-FCS30D classes loaded: {len(GLC_CLASSES)} categories\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {e}\")\n",
    "    print(\"Please run: ee.Authenticate() first if not authenticated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e34652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD STUDY AREA BOUNDARY\n",
    "shapefile_path = \"CEPF Content/data/commondata/fwdcepfwesternghatsprioritizationdatalayers/cepfbnd_prj.shp\"\n",
    "\n",
    "print(\"Loading Western Ghats boundary...\")\n",
    "try:\n",
    "    # Load boundary shapefile\n",
    "    western_ghats = gpd.read_file(shapefile_path)\n",
    "    print(f\"Loaded {western_ghats.shape[0]} polygon(s)\")\n",
    "    print(f\"Original CRS: {western_ghats.crs}\")\n",
    "    \n",
    "    # Convert to WGS84 for Earth Engine compatibility\n",
    "    western_ghats_wgs84 = western_ghats.to_crs('EPSG:4326')\n",
    "    \n",
    "    # Calculate area for verification\n",
    "    area_km2 = western_ghats.to_crs('EPSG:3857').area.sum() / 1e6\n",
    "    print(f\"Total study area: {area_km2:.0f} km²\")\n",
    "    \n",
    "    # Convert to Earth Engine geometry\n",
    "    def convert_to_ee_geometry(gdf):\n",
    "        \"\"\"Convert GeoDataFrame to Earth Engine MultiPolygon\"\"\"\n",
    "        gdf_buffered = gdf.buffer(0.0001).buffer(-0.0001)\n",
    "        union_geom = gdf_buffered.unary_union\n",
    "        \n",
    "        if union_geom.geom_type == 'Polygon':\n",
    "            coords = [list(union_geom.exterior.coords)]\n",
    "            return ee.Geometry.Polygon(coords)\n",
    "        elif union_geom.geom_type == 'MultiPolygon':\n",
    "            polygons = []\n",
    "            for polygon in union_geom.geoms:\n",
    "                coords = [list(polygon.exterior.coords)]\n",
    "                polygons.append(coords)\n",
    "            return ee.Geometry.MultiPolygon(polygons)\n",
    "    \n",
    "    # Convert to Earth Engine geometry\n",
    "    western_ghats_ee = convert_to_ee_geometry(western_ghats_wgs84)\n",
    "    \n",
    "    # Verify Earth Engine geometry\n",
    "    ee_area = western_ghats_ee.area().getInfo() / 1e6\n",
    "    print(f\"Earth Engine area: {ee_area:.0f} km²\")\n",
    "    \n",
    "    area_diff_percent = abs(ee_area - area_km2) / area_km2 * 100\n",
    "    if area_diff_percent < 5:\n",
    "        print(f\"SUCCESS: Geometry conversion successful (difference: {area_diff_percent:.1f}%)\")\n",
    "        STUDY_AREA_KM2 = ee_area\n",
    "    else:\n",
    "        print(f\"WARNING: Significant area difference: {area_diff_percent:.1f}%)\")\n",
    "        STUDY_AREA_KM2 = ee_area\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ERROR loading boundary: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ac843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP GLC-FCS30D CLASSES TO SIMPLIFIED CATEGORIES\n",
    "\n",
    "def map_glc_to_simplified_classes(glc_value):\n",
    "    \"\"\"Map GLC-FCS30D detailed classes to simplified LULC categories\"\"\"\n",
    "    \n",
    "    # Forest classes (50-92)\n",
    "    if glc_value in [51, 52, 61, 62, 71, 72, 81, 82, 91, 92]:\n",
    "        return 1  # Trees/Forest\n",
    "    \n",
    "    # Cropland classes (10-20)\n",
    "    elif glc_value in [10, 11, 12, 20]:\n",
    "        return 4  # Crops\n",
    "    \n",
    "    # Shrubland classes (120-122)\n",
    "    elif glc_value in [120, 121, 122]:\n",
    "        return 5  # Shrub and scrub\n",
    "    \n",
    "    # Grassland (130)\n",
    "    elif glc_value == 130:\n",
    "        return 2  # Grass\n",
    "    \n",
    "    # Sparse vegetation (150-153)\n",
    "    elif glc_value in [150, 152, 153]:\n",
    "        return 7  # Bare\n",
    "    \n",
    "    # Wetlands/Flooded vegetation (181-187)\n",
    "    elif glc_value in [181, 182, 183, 184, 185, 186, 187]:\n",
    "        return 3  # Flooded vegetation\n",
    "    \n",
    "    # Urban/Built (190)\n",
    "    elif glc_value == 190:\n",
    "        return 6  # Built\n",
    "    \n",
    "    # Bare areas (200-202)\n",
    "    elif glc_value in [200, 201, 202]:\n",
    "        return 7  # Bare\n",
    "    \n",
    "    # Water body (210)\n",
    "    elif glc_value == 210:\n",
    "        return 0  # Water\n",
    "    \n",
    "    # Lichen/mosses (140)\n",
    "    elif glc_value == 140:\n",
    "        return 2  # Grass (closest match)\n",
    "    \n",
    "    # Snow/ice (220) - should not occur in Western Ghats\n",
    "    elif glc_value == 220:\n",
    "        return 8  # Snow and ice\n",
    "    \n",
    "    else:\n",
    "        return 7  # Default to Bare for unknown classes\n",
    "\n",
    "# Create mapping dictionary for Earth Engine\n",
    "GLC_TO_SIMPLIFIED = {\n",
    "    # Forest\n",
    "    51: 1, 52: 1, 61: 1, 62: 1, 71: 1, 72: 1, 81: 1, 82: 1, 91: 1, 92: 1,\n",
    "    # Crops\n",
    "    10: 4, 11: 4, 12: 4, 20: 4,\n",
    "    # Shrub\n",
    "    120: 5, 121: 5, 122: 5,\n",
    "    # Grass\n",
    "    130: 2, 140: 2,\n",
    "    # Flooded vegetation\n",
    "    181: 3, 182: 3, 183: 3, 184: 3, 185: 3, 186: 3, 187: 3,\n",
    "    # Built\n",
    "    190: 6,\n",
    "    # Bare\n",
    "    150: 7, 152: 7, 153: 7, 200: 7, 201: 7, 202: 7,\n",
    "    # Water\n",
    "    210: 0,\n",
    "    # Snow/ice\n",
    "    220: 8\n",
    "}\n",
    "\n",
    "# Simplified class names (matching Dynamic World)\n",
    "SIMPLIFIED_CLASSES = {\n",
    "    0: 'Water',\n",
    "    1: 'Trees',\n",
    "    2: 'Grass',\n",
    "    3: 'Flooded vegetation',\n",
    "    4: 'Crops',\n",
    "    5: 'Shrub and scrub',\n",
    "    6: 'Built',\n",
    "    7: 'Bare',\n",
    "    8: 'Snow and ice'\n",
    "}\n",
    "\n",
    "print(\"Class mapping defined\")\n",
    "print(f\"Simplified to {len(SIMPLIFIED_CLASSES)} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTORICAL LULC ANALYSIS FUNCTION\n",
    "\n",
    "def analyze_historical_lulc(year, region_ee):\n",
    "    \"\"\"\n",
    "    Analyze historical LULC using GLC-FCS30D dataset\n",
    "    \n",
    "    Parameters:\n",
    "    - year: Analysis year (1985-2020, preferably 5-year intervals)\n",
    "    - region_ee: Earth Engine geometry for Western Ghats\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with area statistics for each land cover class\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ANALYZING HISTORICAL LULC FOR {year}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Get GLC-FCS30D image for the year\n",
    "        print(f\"Loading GLC-FCS30D data for {year}...\")\n",
    "        \n",
    "        # Use 5-year collection for better temporal coverage\n",
    "        glc_image = glc_fcs_five_year.filter(ee.Filter.eq('year', year)).first()\n",
    "        \n",
    "        # If not found in 5-year collection, try annual\n",
    "        if glc_image is None:\n",
    "            print(f\"   Trying annual collection...\")\n",
    "            glc_image = glc_fcs_annual.filter(ee.Filter.eq('year', year)).first()\n",
    "        \n",
    "        if glc_image is None:\n",
    "            print(f\"ERROR: No data found for {year}\")\n",
    "            return None\n",
    "        \n",
    "        # Get the land cover band\n",
    "        lc_band = glc_image.select('b1')  # Main classification band\n",
    "        \n",
    "        # Clip to study region\n",
    "        lc_clipped = lc_band.clip(region_ee)\n",
    "        \n",
    "        print(f\"   Data loaded successfully\")\n",
    "        \n",
    "        # Remap GLC classes to simplified categories\n",
    "        print(f\"   Remapping {len(GLC_TO_SIMPLIFIED)} GLC classes to simplified categories...\")\n",
    "        \n",
    "        from_values = list(GLC_TO_SIMPLIFIED.keys())\n",
    "        to_values = list(GLC_TO_SIMPLIFIED.values())\n",
    "        \n",
    "        lc_simplified = lc_clipped.remap(from_values, to_values, 7)  # Default to Bare (7)\n",
    "        \n",
    "        # Calculate areas for each simplified class\n",
    "        print(f\"   Calculating areas for all land cover classes...\")\n",
    "        \n",
    "        results = {'year': year, 'dataset': 'GLC-FCS30D'}\n",
    "        pixel_area = ee.Image.pixelArea()\n",
    "        \n",
    "        for class_id, class_name in SIMPLIFIED_CLASSES.items():\n",
    "            try:\n",
    "                # Create mask for this class\n",
    "                class_mask = lc_simplified.eq(class_id)\n",
    "                \n",
    "                # Calculate area\n",
    "                area_m2 = pixel_area.updateMask(class_mask).reduceRegion(\n",
    "                    reducer=ee.Reducer.sum(),\n",
    "                    geometry=region_ee,\n",
    "                    scale=30,  # 30m resolution for GLC-FCS30D\n",
    "                    maxPixels=1e10,\n",
    "                    bestEffort=True\n",
    "                ).getInfo()\n",
    "                \n",
    "                # Convert to km²\n",
    "                area_km2 = area_m2.get('area', 0) / 1e6\n",
    "                results[class_name] = area_km2\n",
    "                \n",
    "                if area_km2 > 0.1:\n",
    "                    percentage = (area_km2 / STUDY_AREA_KM2) * 100\n",
    "                    print(f\"      {class_name}: {area_km2:.1f} km² ({percentage:.1f}%)\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"      ERROR calculating {class_name}: {e}\")\n",
    "                results[class_name] = 0\n",
    "        \n",
    "        # Calculate total area and percentages\n",
    "        total_area = sum([v for k, v in results.items() \n",
    "                         if k not in ['year', 'dataset'] and isinstance(v, (int, float))])\n",
    "        results['total_area_km2'] = total_area\n",
    "        \n",
    "        # Add percentage calculations\n",
    "        for class_name in SIMPLIFIED_CLASSES.values():\n",
    "            if class_name in results and total_area > 0:\n",
    "                percentage = (results[class_name] / total_area) * 100\n",
    "                results[f'{class_name}_percent'] = percentage\n",
    "        \n",
    "        # Summary\n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        print(f\"SUCCESS: {year} analysis completed in {elapsed:.1f} minutes\")\n",
    "        print(f\"Total classified area: {total_area:.1f} km² ({(total_area/STUDY_AREA_KM2)*100:.1f}% of study area)\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        print(f\"ERROR: {year} analysis FAILED after {elapsed:.1f} minutes\")\n",
    "        print(f\"Error details: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Historical LULC analysis function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13bcbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN HISTORICAL ANALYSIS FOR 5-YEAR INTERVALS (1985-2020)\n",
    "\n",
    "# Define analysis years (5-year intervals)\n",
    "historical_years = [1985, 1990, 1995, 2000, 2005, 2010, 2015, 2020]\n",
    "\n",
    "print(f\"Starting historical analysis for {len(historical_years)} years...\")\n",
    "print(f\"Years: {historical_years}\")\n",
    "print(\"This may take 30-60 minutes depending on Earth Engine quota\")\n",
    "\n",
    "historical_results = []\n",
    "\n",
    "for year in historical_years:\n",
    "    result = analyze_historical_lulc(year, western_ghats_ee)\n",
    "    if result:\n",
    "        historical_results.append(result)\n",
    "        print(f\"SUCCESS: {year} analysis complete\")\n",
    "    else:\n",
    "        print(f\"FAILED: {year} analysis failed\")\n",
    "    \n",
    "    # Brief pause between requests\n",
    "    time.sleep(5)\n",
    "\n",
    "if historical_results:\n",
    "    # Convert to DataFrame\n",
    "    historical_df = pd.DataFrame(historical_results)\n",
    "    \n",
    "    print(f\"\\nHistorical analysis complete for {len(historical_results)} years\")\n",
    "    print(\"\\nKey results:\")\n",
    "    display(historical_df[['year', 'Trees', 'Built', 'Crops', 'total_area_km2']].round(1))\n",
    "    \n",
    "    # Save results\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_file = f'outputs/western_ghats_historical_lulc_{timestamp}.csv'\n",
    "    historical_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nResults saved: {output_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo results obtained - check Earth Engine connection and data availability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71507225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AND COMBINE WITH DYNAMIC WORLD RESULTS\n",
    "\n",
    "print(\"Loading Dynamic World results for comprehensive analysis...\")\n",
    "\n",
    "try:\n",
    "    # Load Dynamic World results\n",
    "    dw_files = [f for f in os.listdir('outputs') \n",
    "                if 'lulc_analysis_results' in f and f.endswith('.csv')]\n",
    "    \n",
    "    if dw_files:\n",
    "        dw_df = pd.read_csv(f'outputs/{sorted(dw_files)[-1]}')\n",
    "        dw_df['dataset'] = 'Dynamic World'\n",
    "        print(f\"Loaded Dynamic World results: {len(dw_df)} years\")\n",
    "        print(f\"Years: {sorted(dw_df['year'].unique())}\")\n",
    "        \n",
    "        # Combine datasets\n",
    "        combined_df = pd.concat([historical_df, dw_df], ignore_index=True)\n",
    "        combined_df = combined_df.sort_values('year').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nCombined dataset: {len(combined_df)} years total\")\n",
    "        print(f\"Year range: {int(combined_df['year'].min())}-{int(combined_df['year'].max())}\")\n",
    "        \n",
    "        # Save combined results\n",
    "        combined_file = f'outputs/western_ghats_combined_lulc_{timestamp}.csv'\n",
    "        combined_df.to_csv(combined_file, index=False)\n",
    "        print(f\"Combined results saved: {combined_file}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No Dynamic World results found\")\n",
    "        combined_df = historical_df.copy()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading Dynamic World results: {e}\")\n",
    "    combined_df = historical_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5aaf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE STATISTICAL ANALYSIS\n",
    "\n",
    "print(\"COMPREHENSIVE STATISTICAL ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Overall statistics\n",
    "print(\"\\n1. OVERALL SUMMARY\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Analysis period: {int(combined_df['year'].min())}-{int(combined_df['year'].max())}\")\n",
    "print(f\"Total years analyzed: {len(combined_df)}\")\n",
    "print(f\"Datasets used: {combined_df['dataset'].unique()}\")\n",
    "print(f\"Study area: {STUDY_AREA_KM2:.0f} km²\")\n",
    "\n",
    "# Land cover statistics by class\n",
    "print(\"\\n2. LAND COVER STATISTICS BY CLASS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for class_name in SIMPLIFIED_CLASSES.values():\n",
    "    if class_name in combined_df.columns and f'{class_name}_percent' in combined_df.columns:\n",
    "        \n",
    "        # Get first and last year data\n",
    "        first_year = combined_df.iloc[0]\n",
    "        last_year = combined_df.iloc[-1]\n",
    "        \n",
    "        # Calculate changes\n",
    "        area_change = last_year[class_name] - first_year[class_name]\n",
    "        pct_point_change = last_year[f'{class_name}_percent'] - first_year[f'{class_name}_percent']\n",
    "        \n",
    "        if first_year[class_name] > 0:\n",
    "            relative_change = (area_change / first_year[class_name]) * 100\n",
    "        else:\n",
    "            relative_change = 0\n",
    "        \n",
    "        print(f\"\\n{class_name}:\")\n",
    "        print(f\"   {int(first_year['year'])}: {first_year[class_name]:.1f} km² ({first_year[f'{class_name}_percent']:.1f}%)\")\n",
    "        print(f\"   {int(last_year['year'])}: {last_year[class_name]:.1f} km² ({last_year[f'{class_name}_percent']:.1f}%)\")\n",
    "        print(f\"   Change: {area_change:+.1f} km² ({pct_point_change:+.1f} percentage points)\")\n",
    "        print(f\"   Relative change: {relative_change:+.1f}%\")\n",
    "\n",
    "# Temporal trends\n",
    "print(\"\\n3. TEMPORAL TRENDS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Calculate annual rates of change for key classes\n",
    "key_classes = ['Trees', 'Built', 'Crops', 'Bare']\n",
    "\n",
    "for class_name in key_classes:\n",
    "    if f'{class_name}_percent' in combined_df.columns:\n",
    "        \n",
    "        # Calculate year-over-year changes\n",
    "        combined_df[f'{class_name}_change'] = combined_df[f'{class_name}_percent'].diff()\n",
    "        \n",
    "        # Statistics\n",
    "        mean_change = combined_df[f'{class_name}_change'].mean()\n",
    "        std_change = combined_df[f'{class_name}_change'].std()\n",
    "        max_increase = combined_df[f'{class_name}_change'].max()\n",
    "        max_decrease = combined_df[f'{class_name}_change'].min()\n",
    "        \n",
    "        print(f\"\\n{class_name}:\")\n",
    "        print(f\"   Mean annual change: {mean_change:+.3f} percentage points/year\")\n",
    "        print(f\"   Std deviation: {std_change:.3f}\")\n",
    "        print(f\"   Maximum increase: {max_increase:+.3f} percentage points\")\n",
    "        print(f\"   Maximum decrease: {max_decrease:+.3f} percentage points\")\n",
    "\n",
    "# Dataset comparison (overlap years)\n",
    "print(\"\\n4. DATASET COMPARISON\")\n",
    "print(\"-\" * 80\")\n",
    "\n",
    "overlap_years = [2018, 2019, 2020]\n",
    "print(f\"Comparing datasets for overlap years: {overlap_years}\")\n",
    "\n",
    "for year in overlap_years:\n",
    "    year_data = combined_df[combined_df['year'] == year]\n",
    "    if len(year_data) > 0:\n",
    "        print(f\"\\n{int(year)}:\")\n",
    "        for class_name in key_classes:\n",
    "            if class_name in year_data.columns:\n",
    "                values = year_data[class_name].values\n",
    "                print(f\"   {class_name}: {values[0]:.1f} km²\")\n",
    "\n",
    "# Save statistical summary\n",
    "stats_summary = {\n",
    "    'analysis_info': {\n",
    "        'analysis_date': datetime.now().isoformat(),\n",
    "        'study_area_km2': float(STUDY_AREA_KM2),\n",
    "        'years_analyzed': combined_df['year'].tolist(),\n",
    "        'datasets': combined_df['dataset'].unique().tolist(),\n",
    "        'temporal_range': f\"{int(combined_df['year'].min())}-{int(combined_df['year'].max())}\"\n",
    "    },\n",
    "    'land_cover_changes': {}\n",
    "}\n",
    "\n",
    "for class_name in SIMPLIFIED_CLASSES.values():\n",
    "    if class_name in combined_df.columns:\n",
    "        first_year = combined_df.iloc[0]\n",
    "        last_year = combined_df.iloc[-1]\n",
    "        \n",
    "        stats_summary['land_cover_changes'][class_name] = {\n",
    "            'initial_area_km2': float(first_year[class_name]),\n",
    "            'final_area_km2': float(last_year[class_name]),\n",
    "            'absolute_change_km2': float(last_year[class_name] - first_year[class_name]),\n",
    "            'percentage_point_change': float(last_year[f'{class_name}_percent'] - first_year[f'{class_name}_percent']) if f'{class_name}_percent' in combined_df.columns else None\n",
    "        }\n",
    "\n",
    "stats_file = f'outputs/western_ghats_statistical_summary_{timestamp}.json'\n",
    "with open(stats_file, 'w') as f:\n",
    "    json.dump(stats_summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nStatistical summary saved: {stats_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE COMPREHENSIVE VISUALIZATIONS\n",
    "\n",
    "print(\"Creating comprehensive visualizations...\")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create figure with multiple subplots\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 1. Long-term trends for key classes\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "for class_name in ['Trees', 'Built', 'Crops']:\n",
    "    if f'{class_name}_percent' in combined_df.columns:\n",
    "        ax1.plot(combined_df['year'], combined_df[f'{class_name}_percent'], \n",
    "                marker='o', linewidth=2, markersize=6, label=class_name)\n",
    "\n",
    "ax1.set_title('Long-term Land Cover Trends (1985-2023)', fontweight='bold', fontsize=12)\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Percentage of Total Area (%)')\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Built-up area expansion\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "if 'Built' in combined_df.columns:\n",
    "    bars = ax2.bar(combined_df['year'], combined_df['Built'], \n",
    "                   color='#D32F2F', alpha=0.7, width=1.5)\n",
    "    ax2.set_title('Built-up Area Expansion', fontweight='bold', fontsize=12)\n",
    "    ax2.set_xlabel('Year')\n",
    "    ax2.set_ylabel('Built-up Area (km²)')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Forest cover trends\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "if 'Trees' in combined_df.columns:\n",
    "    ax3.plot(combined_df['year'], combined_df['Trees'], \n",
    "            marker='o', color='#2E7D32', linewidth=2, markersize=6)\n",
    "    ax3.fill_between(combined_df['year'], combined_df['Trees'], alpha=0.3, color='#2E7D32')\n",
    "    ax3.set_title('Forest Cover Over Time', fontweight='bold', fontsize=12)\n",
    "    ax3.set_xlabel('Year')\n",
    "    ax3.set_ylabel('Forest Area (km²)')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Rate of change analysis\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "if 'Built_change' in combined_df.columns:\n",
    "    changes = combined_df[['year', 'Trees_change', 'Built_change', 'Crops_change']].dropna()\n",
    "    width = 0.25\n",
    "    x = np.arange(len(changes))\n",
    "    \n",
    "    ax4.bar(x - width, changes['Trees_change'], width, label='Trees', color='#2E7D32', alpha=0.7)\n",
    "    ax4.bar(x, changes['Built_change'], width, label='Built', color='#D32F2F', alpha=0.7)\n",
    "    ax4.bar(x + width, changes['Crops_change'], width, label='Crops', color='#F57C00', alpha=0.7)\n",
    "    \n",
    "    ax4.set_title('Year-over-Year Changes', fontweight='bold', fontsize=12)\n",
    "    ax4.set_xlabel('Year')\n",
    "    ax4.set_ylabel('Change (percentage points)')\n",
    "    ax4.set_xticks(x[::2])\n",
    "    ax4.set_xticklabels(changes['year'].astype(int).values[::2], rotation=45)\n",
    "    ax4.legend()\n",
    "    ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Land cover composition (latest year)\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "latest = combined_df.iloc[-1]\n",
    "classes_to_plot = ['Trees', 'Crops', 'Built', 'Shrub and scrub', 'Water', 'Grass', 'Bare']\n",
    "areas = [latest.get(cls, 0) for cls in classes_to_plot]\n",
    "colors_plot = ['#2E7D32', '#F57C00', '#D32F2F', '#795548', '#1976D2', '#689F38', '#757575']\n",
    "\n",
    "# Filter out zero values\n",
    "non_zero = [(cls, area, col) for cls, area, col in zip(classes_to_plot, areas, colors_plot) if area > 0]\n",
    "if non_zero:\n",
    "    classes_filtered, areas_filtered, colors_filtered = zip(*non_zero)\n",
    "    wedges, texts, autotexts = ax5.pie(areas_filtered, labels=classes_filtered, autopct='%1.1f%%',\n",
    "                                       colors=colors_filtered, startangle=90)\n",
    "    ax5.set_title(f'Land Cover Composition {int(latest[\"year\"])}', fontweight='bold', fontsize=12)\n",
    "\n",
    "# 6. Cumulative change from baseline\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "baseline = combined_df.iloc[0]\n",
    "for class_name in ['Trees', 'Built', 'Crops']:\n",
    "    if class_name in combined_df.columns:\n",
    "        cumulative_change = combined_df[class_name] - baseline[class_name]\n",
    "        ax6.plot(combined_df['year'], cumulative_change, \n",
    "                marker='o', linewidth=2, markersize=6, label=class_name)\n",
    "\n",
    "ax6.set_title('Cumulative Change from 1985 Baseline', fontweight='bold', fontsize=12)\n",
    "ax6.set_xlabel('Year')\n",
    "ax6.set_ylabel('Change in Area (km²)')\n",
    "ax6.legend()\n",
    "ax6.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save comprehensive visualization\n",
    "viz_file = f'outputs/western_ghats_comprehensive_analysis_{timestamp}.png'\n",
    "plt.savefig(viz_file, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Comprehensive visualization saved: {viz_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b16372",
   "metadata": {},
   "source": [
    "## Analysis Complete\n",
    "\n",
    "The historical LULC analysis has been completed successfully. Key outputs:\n",
    "\n",
    "1. **Historical LULC data (1985-2020)** at 5-year intervals using GLC-FCS30D\n",
    "2. **Combined dataset** integrating GLC-FCS30D and Dynamic World results\n",
    "3. **Comprehensive statistical analysis** with detailed change metrics\n",
    "4. **Visualizations** showing long-term trends and patterns\n",
    "\n",
    "Next steps:\n",
    "- Generate interactive HTML comparison tool\n",
    "- Create detailed statistical reports\n",
    "- Prepare outputs for presentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
